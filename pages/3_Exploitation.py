from pydub import AudioSegment
from torchvision.models import vit_b_32
from utils.models import Lumiere
from utils.utils import get_spectrogram, display_spectrogram

import json
import numpy as np
import os
import streamlit as st
import torch
import torch.nn as nn
import torchvision.transforms as Tv

## Load model
f = open('class_map.json')
class_map = json.load(f)
inv_class_mapping = {v: k for k, v in class_map.items()}
model = vit_b_32()
model.heads.head = nn.Linear(768, len(class_map))
criterion = nn.CrossEntropyLoss()
transform = Tv.Compose([Tv.ToTensor(),
                                 #lambda x : x/255.0,
                                 lambda x : torch.vstack((x,x,x))])
 

st.title("Use your model !")
st.write("Here you can use your model to classify a new audio file"
         "\nYou can upload a file or enter the relative path to the file"
         "\nYou can also enter the name to the model if you want to use a model that you trained before"
         "\nIf you don't know what to put, just leave the default values"
         "\nEnjoy !")

st.subheader("Model informations")
last_run = st.checkbox("Use the last run", value=True)
model_name = st.text_input("Name of the model", "first_run")
st.info("enter the name of the model if you want to use a model that you trained before")
model_pl = None
        
st.subheader("use the model")
uploaded_file = st.file_uploader("Upload a file", type=["wav", "mp3", "ogg"])
if uploaded_file is not None:
        #load model
        st.write('Loading model...')
        checkpoints = os.listdir(os.path.join("model", model_name))
        checkpoints.sort()
        print(os.path.join("model", model_name, checkpoints[-1]))
        model_pl = Lumiere(len(class_map), False).load_from_checkpoint(os.path.join("model", model_name, checkpoints[-1]))
        st.write('Model loaded')
        
        #convertion of the file
        st.write("File uploaded")
        file = AudioSegment.from_file(uploaded_file)
        sr = file.frame_rate
        samples = file.get_array_of_samples()
        samples = np.array(samples, dtype=np.float32)
        f = open('preprocinfo.json')
        args = json.load(f)
        args["n_mels"] = 224
        args["hop_length"] = int(sr * 5/ (args["n_mels"] -1))
        specs = get_spectrogram(samples, sr, 5, args)
        specs = [transform(spec) for spec in specs]
        specs = torch.stack(specs)
        print(specs.shape)
        preds = model_pl(specs)
        preds = torch.argmax(preds, dim=1)
        preds = preds.tolist()
        st.write("the class predicted is : ", inv_class_mapping[max(preds, key = preds.count)])
        st.subheader("Spectrogram")
        preds = [inv_class_mapping[pred] for pred in preds]
        st.pyplot(display_spectrogram(specs,preds))
        
    
    